## 11.5 用传输保证提供容错能力

考虑以下的场景，我们有两个基于事件的系统，它们之间唯一的集成点是一个Kafka主题。我们的出库服务通过Kafka的异步消费者逻辑产生一个付费事件。然后， 我们的账单服务从主题中消费这个数据并处理它，如图11.15所示。

![11.15](11-15.svg)

**图11.15 基于事件的出库和账单服务**

假设出库服务平均每秒发送50个请求。账单服务的SLA保证它能每秒处理100个请求，如图11.16所示。假如账单服务故障了或者在部署新版本时停止了工作，那它在这段时间里就不能消费Kafka主题中的事件了。这两个服务之间的解耦合让我们的出库服务可以容忍诸如此类的错误。

![11.16](11-16.svg)

**图11.16 在Kafka主题内缓存事件**

即使账单服务停止工作了，出库服务依然可以继续产生付费事件。只不过这些事件会被保留在Kafka主题内。假设账单服务在5秒后重启并开始正常工作。在这段时间内，出库服务往Kafka主题发送了250个事件（每秒50次请求 * 5秒）。这些事件会被缓存在Kafka主题内。消费者重新上线后会继续处理缓存的事件。

如果账单服务工作在至少一次的传输保证下，那它就要从最后一个已经处理的事件之后开始继续处理。这意味着消费者需要正确提交偏移量（在处理逻辑成功以后），且偏移量重置策略应该被设置为earliest。缓存在主题内的250个事件需要跟来自出库服务的正常流量一起被处理；否则账单服务就没办法跟上后续的流量了。

我们已经知道，账单服务每秒可以处理100个请求。但它在正常工作下还需要每秒消费50个事件。也就是说，账单服务需要额外的2.5秒来处理缓存的事件。在这段时间，我们会观察到处理的时延达到了2.5秒甚至更高。这是因为账单服务需要在处理新流量之前先处理缓存的事件，而作为生产者的出库服务还在继续发送事件。过了一段时间之后，所有缓存的事件都已经被消费掉了，我们的两个应用程序就会开始以标准的时延和流量继续处理整个业务流。

同样的解决方案可以用于处理预料之外的流量暴涨。假设我们的出库服务突然开始每秒产生200个事件。此时账单服务无法跟上这样的流量，因为它只提供了每秒处理100次请求的SLA。不过，暴涨只是暂时的，额外的事件会被缓存在Kafka主题内。当流量回归正常时，账单服务就能处理那些额外的数据并在一段时间后回归平时的流量。

只要我们有一个发布-订阅的架构和一个可以缓存流量的组件，我们就可以为自己的系统构建这样的容错能力。除此之外，我们还需要搞明白这些组件能提供哪些传输保证。然后才能根据我们的需要选择适当的传输语义。

这个解决方案第二个关键点在于消费者处理额外流量的能力。如果消费者的SLA并不比生产者高很多，用于恢复处理的时间就会很长。消费者需要能在处理普通输入流量的同时处理额外的缓存流量。否则一旦它发生了部分故障，流量的处理就会跟不上。现在让我们总结一下本章所学。


## 总结

* 发布-订阅架构让我们可以创建松耦合的异步系统，用恰当的传输保证提升容错能力。
* 使用事件队列让我们有能力创建事件驱动的架构。互联的服务越多，这个架构给我们带来的好处越大。
* 我们可以在生产者和消费者端判断并控制传输语义。
* 我们可以微调分布式系统的一致性和可用性。
* 我们可以在消费者代码中实现Kafka的至少一次和至多一次传输保证：
    * 在至少一次的传输保证下，细粒度地提交偏移量可以减少消费者端的重复
    * 在至多一次的传输保证下，当发生故障时，存在有些事件没有被处理的风险
* 如果将队列功能拆分成N个独立系统，我们的系统就既可以获得松耦合与异步容错，又不会导致单点故障。
* 我们可以用事务获得最终恰好一次保证。不过当我们的流水线上的服务越来越多，架构越来越复杂，想要实现最终恰好一次也会变得越来越复杂甚至无法实现。