## 8.2 数据的分区和切割

我们已经在上一节看过数据本地性这一技术是如何做到让我们可以更轻松地扩展大数据的处理。在真实世界的大数据处理程序中，我们需要存储和处理的数据量往往达到上千TB或PB。我们不可能在一台物理机器上存储这样大量的数据。我们需要一种方法将数据切割存储到N个数据节点上。数据切割的技术有很多，本节将要给大家展示的数据切割技术叫做数据分区。


对于线上处理的数据源（比如数据库），你可以选择某种ID（比如用户ID）作为分区的关键字，并在一台指定节点上存储一段范围内的所有用户。比如说，假设你有1000个用户ID和5个数据节点，第一个节点可以存储0到200的ID，第二个节点存储201到400，以此类推。


在选择分区策略时，你要当心不要引入数据倾斜。数据倾斜指的是大多数的数据都集中在某一个ID上，或着都集中在属于同一节点的一组ID上。比如说，假设我们ID为10的用户贡献了80%的流量并产生了80%的数据。这意味着我们80%的数据都存储在第一个节点，我们的分区策略就不是最优的。在最差情况下，这个用户的数据量可能大到无法存储在一个数据节点上。这里的关键点在于，当我们在线处理数据时，数据分区需要根据读取或写入的模式来进行优化。


### 8.2.1 线下大数据分区

现在让我们集中讨论线下大数据处理的分区。一个大数据系统通常需要在一个不固定的期限内存储各种历史数据（冷数据）。我们希望存储的时间越长越好，因为当数据刚刚产生的时候，我们可能还没有意识到它所具备的商业价值。


比如说，我们可能保存了用户所有的请求数据，包括HTTP头部，但是当这些数据被保存下来的时候，可能还没有什么地方用到这些HTTP头部。但是在将来，我们可能决定要创建一个工具来根据用户所使用的设备（比如安卓，iOS）对用户群体进行分析。这类信息就保存在HTTP头部。由于我们保存了这些原始数据，我们就可以基于历史数据来执行我们新的分析逻辑。值得注意的是这些数据在很长一段时间里都没有被用到。


现在既然我们的系统需要存储大量暂时还用不到的信息，我们就要考虑将这部分数据存放在冷存储里。在大数据处理应用中，这通常意味着数据会被保存在Hadoop分布式文件系统（HDFS）。这也意味着我们应该用一种通用的方式来进行数据分区。因为我们无法预知数据如何被读取，也就无法根据数据的读取模式优化我们的分区策略。


基于上述理由，线下大数据处理最通用的分区策略是基于日期分区。假设我们有一个系统在文件系统的`/users`目录存放了用户数据，并在`/clicks`目录存放了点击流数据。一开始我们只想要分析用户数据。假设我们存储了100亿条用户数据，数据搜集开始于2017年并一直搜集至今。


我们选择的分区策略基于日期。这意味着我们的分区关键字从年开始，也就是说，我们会分2017，2018，2019和2020这四个区。如果我们的数据需求比较小，那么以年份分区可能就足够了。这样，我们的用户数据会以`/users/2017`，`/users/2018`这样的目录保存在文件系统上。
